# -*- coding: utf-8 -*-
"""
/***************************************************************************
 ML-CLAS
                                 A QGIS plugin
 This plugin can be used to apply classification on agricultural fields
 Generated by Plugin Builder: http://g-sherman.github.io/Qgis-Plugin-Builder/
                              -------------------
        begin                : 2023-03-04
        git sha              : $Format:%H$
        copyright            : (C) 2023 by Sravani Duvvuri
        email                : sravanidvr@gmail.com
 ***************************************************************************/

/***************************************************************************
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
 *   the Free Software Foundation; either version 2 of the License, or     *
 *   (at your option) any later version.                                   *
 *                                                                         *
 ***************************************************************************/
"""

#------------------------|
# Library Imports        |
#------------------------|

from qgis.PyQt.QtCore import QSettings, QTranslator, QCoreApplication
from qgis.PyQt.QtGui import QIcon
from qgis.PyQt.QtWidgets import QAction, QFileDialog 

import processing 
from qgis.core import QgsRasterLayer, QgsVectorLayer, QgsProject, QgsVectorFileWriter, QgsCoordinateReferenceSystem
from osgeo import gdal, ogr

# Initialize Qt resources from file resources.py
from .resources import *
# Import the code for the dialog
from .classification_dialog import ClassificationDialog, HelpDialog, TWDTWHelpDialog
import os
import sys

import numpy as np
import pandas as pd
import geopandas as gpd
import rasterio
from shapely.geometry import Point, mapping
from rasterstats import zonal_stats
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from rasterio.mask import mask
from skimage.feature import graycomatrix, graycoprops
import matplotlib.pyplot as plt

class Classification:
    """QGIS Plugin Implementation."""

    def __init__(self, iface):

        """Constructor.

        :param iface: An interface instance that will be passed to this class
            which provides the hook by which you can manipulate the QGIS
            application at run time.
        :type iface: QgsInterface
        """

        self.iface = iface
        self.plugin_dir = os.path.dirname(__file__)
        locale = QSettings().value('locale/userLocale')[0:2]
        locale_path = os.path.join(
            self.plugin_dir,
            'i18n',
            'ML-CLAS_{}.qm'.format(locale))

        if os.path.exists(locale_path):
            self.translator = QTranslator()
            self.translator.load(locale_path)
            QCoreApplication.installTranslator(self.translator)

        self.actions = []
        self.menu = self.tr(u'&ML-CLAS')
        self.first_start = None

    def tr(self, message):

        """Get the translation for a string using Qt translation API.

        We implement this ourselves since we do not inherit QObject.

        :param message: String for translation.
        :type message: str, QString

        :returns: Translated version of message.
        :rtype: QString
        """

        return QCoreApplication.translate('ML-CLAS', message)

    def add_action(self, icon_path, text, callback, enabled_flag=True,
                  add_to_menu=True, add_to_toolbar=True, status_tip=None,
                  whats_this=None, parent=None):

        """Add a toolbar icon to the toolbar.

        :param icon_path: Path to the icon for this action. Can be a resource
            path (e.g. ':/plugins/foo/bar.png') or a normal file system path.
        :type icon_path: str

        :param text: Text that should be shown in menu items for this action.
        :type text: str

        :param callback: Function to be called when the action is triggered.
        :type callback: function

        :param enabled_flag: A flag indicating if the action should be enabled
            by default. Defaults to True.
        :type enabled_flag: bool

        :param add_to_menu: Flag indicating whether the action should also
            be added to the menu. Defaults to True.
        :type add_to_menu: bool

        :param add_to_toolbar: Flag indicating whether the action should also
            be added to the toolbar. Defaults to True.
        :type add_to_toolbar: bool

        :param status_tip: Optional text to show in a popup when mouse pointer
            hovers over the action.
        :type status_tip: str

        :param parent: Parent widget for the new action. Defaults None.
        :type parent: QWidget

        :param whats_this: Optional text to show in the status bar when the
            mouse pointer hovers over the action.

        :returns: The action that was created. Note that the action is also
            added to self.actions list.
        :rtype: QAction
        """

        icon = QIcon(icon_path)
        action = QAction(icon, text, parent)
        action.triggered.connect(callback)
        action.setEnabled(enabled_flag)

        if status_tip is not None:
            action.setStatusTip(status_tip)
        if whats_this is not None:
            action.setWhatsThis(whats_this)
        if add_to_toolbar:
            self.iface.addToolBarIcon(action)
        if add_to_menu:
            self.iface.addPluginToMenu(self.menu, action)

        self.actions.append(action)
        return action

    def initGui(self):

        """Create the menu entries and toolbar icons inside the QGIS GUI."""

        icon_path = ':/plugins/classification/icon.png'
        self.add_action(
            icon_path,
            text=self.tr(u'ML-CLAS'),
            callback=self.run,
            parent=self.iface.mainWindow())
        self.first_start = True

    def unload(self):
        for action in self.actions:
            self.iface.removePluginMenu(
                self.tr(u'&ML-CLAS'),
                action)
            self.iface.removeToolBarIcon(action)

    #------------------------|
    # UI Selection Methods   |
    #------------------------|

    def select_input_rasters(self):
        filenames, _filter = QFileDialog.getOpenFileNames(self.dlg, "Select input raster files ","", '*.*')
        self.dlg.leInputRaster.setText(';'.join(filenames))
        if filenames:
            self.set_coordinates(filenames[0])

    def select_input_rasters_twdtw(self):
        filenames, _filter = QFileDialog.getOpenFileNames(self.dlg, "Select input raster files ","", '*.*')
        self.dlg.leInputRaster_twdtw.setText(';'.join(filenames))
        if filenames:
            self.set_coordinates(filenames[0])

    def select_input_vector(self):
        filename, _filter = QFileDialog.getOpenFileName(self.dlg, "Select input vector file ","", '*.*')
        self.dlg.leInputVector.setText(filename)

    def select_input_vector_twdtw(self):
        filename, _filter = QFileDialog.getOpenFileName(self.dlg, "Select input vector file ","", '*.*')
        self.dlg.leInputVector_twdtw.setText(filename)

    def select_train_points(self):
        filename, _filter = QFileDialog.getOpenFileName(self.dlg, "Select training points file ","", '*.*')
        self.dlg.lePoints.setText(filename)

    def select_output_folder(self):
        flags = QFileDialog.ShowDirsOnly
        dirpath = str(QFileDialog.getExistingDirectory(self.dlg, 'Choose a output folder', '', flags))
        self.dlg.leOutput.setText(dirpath)

    def select_output_folder_twdtw(self):
        flags = QFileDialog.ShowDirsOnly
        dirpath = str(QFileDialog.getExistingDirectory(self.dlg, 'Choose a output folder', '', flags))
        self.dlg.leOutput_twdtw.setText(dirpath)

    def select_timeline_twdtw(self):
        filename, _filter = QFileDialog.getOpenFileName(self.dlg, "Select timeline file ","", '*.*')
        self.dlg.leTimeline_twdtw.setText(filename)

    def select_sample_projection_twdtw(self):
        filename, _filter = QFileDialog.getOpenFileName(self.dlg, "Select sample projection file ","", '*.*')
        self.dlg.leSP_twdtw.setText(filename)

    def select_field_samples_twdtw(self):
        filename, _filter = QFileDialog.getOpenFileName(self.dlg, "Select field samples file ","", '*.*')
        self.dlg.leFieldSamples_twdtw.setText(filename)

    def set_coordinates(self, file):

        ''' layer extent '''

        lyr = QgsRasterLayer(file)
        if not lyr.isValid():
            print(f"layer {file} failed to load")
            return
        self.dlg.leMinX.setText(str(lyr.extent().xMinimum()))
        self.dlg.leMinY.setText(str(lyr.extent().yMinimum()))
        self.dlg.leMaxX.setText(str(lyr.extent().xMaximum()))
        self.dlg.leMaxY.setText(str(lyr.extent().yMaximum()))

    def openHelpTab(self):
        self.sc = HelpDialog()
        self.sc.show()

    def openTWDTWHelpTab(self):
        self.sc = TWDTWHelpDialog()
        self.sc.show()

    def on_algorithm_changed(self, text):
        if text in ["Support Vector Machine", "Random-Forest"]:
            self.dlg.stackedWidget.setCurrentIndex(0)
        elif text == "TWDTW":
            self.dlg.stackedWidget.setCurrentIndex(1)

    #------------------------|
    # Preprocessing Methods  |
    #------------------------|

    def preProcessRaster(self, input_rasters, input_vector, output_folder, processed_raster_output, skip_nodata_value=False):
        rasters_output_folder = os.path.join(output_folder, "rasters")
        os.makedirs(rasters_output_folder, exist_ok=True)

        processed_rasters = []
        for index, input_raster in enumerate(sorted(input_rasters.split(";"))):
            print("RASTER LAYER -", index+1)
            vector_copy = os.path.join(rasters_output_folder, f"copy_{index+1}.shp")
            result = self.copyVectorFile(input_vector, vector_copy)
            if result == "error":
                continue

            zonal_parameters = {
                'INPUT_RASTER': input_raster,
                'RASTER_BAND': 1,
                'INPUT_VECTOR': vector_copy,
                'COLUMN_PREFIX': "_",
                'STATS': 2,  # for mean
            }
            print("zonal statistics")
            processing.run("qgis:zonalstatistics", zonal_parameters)

            inputRaster = QgsRasterLayer(input_raster)
            pixelSizeX = inputRaster.rasterUnitsPerPixelX()
            pixelSizeY = inputRaster.rasterUnitsPerPixelY()
            rasterized_output = os.path.join(rasters_output_folder, f"processed_{os.path.basename(input_raster)}")

            rasterize_parameters = {
                'INPUT': vector_copy,
                'FIELD': "_mean",
                'BURN': 0,
                'UNITS': 1,
                'WIDTH': pixelSizeX,
                'HEIGHT': pixelSizeY,
                'EXTENT': vector_copy,
                'NODATA': 0,
                'OUTPUT': rasterized_output,
            }
            print("rasterize")
            processing.run("gdal:rasterize", rasterize_parameters)
            processed_rasters.append(rasterized_output)

        merge_parameters = {
            "INPUT": processed_rasters,
            "SEPARATE": True if skip_nodata_value else False,
            "NODATA_INPUT": 0 if not skip_nodata_value else None,
            "NODATA_OUTPUT": 0 if not skip_nodata_value else None,
            "OUTPUT": processed_raster_output,
        }
        print("merge rasters")
        processing.run("gdal:merge", merge_parameters)
        return processed_raster_output

    def copyVectorFile(self, input_vector, output_vector):
        vector_layer = QgsVectorLayer(input_vector, "vector_layer", "ogr")
        writer = QgsVectorFileWriter(output_vector, "UTF-8", vector_layer.fields(), 
                                   vector_layer.wkbType(), vector_layer.crs(), "ESRI Shapefile")
        if writer.hasError() != QgsVectorFileWriter.NoError:
            print("Error creating output vector file:", writer.errorMessage())
            return "error"
        for feature in vector_layer.getFeatures():
            writer.addFeature(feature)
        del writer
        return "success"


    #----------------------------------|
    # Classification Methods (RF/SVM)  |
    #----------------------------------|

    def classify_custom(self):
        print("classification RF_SVM initiated")
        input_rasters = self.dlg.leInputRaster.text()
        input_vector = self.dlg.leInputVector.text()
        train_points = self.dlg.lePoints.text()
        output_folder = self.dlg.leOutput.text()
        label_field_name = self.dlg.leField.text()
        split_percent = float()
        train_algorithm = "RF" if self.dlg.cbAlgorithm.currentText() == "Random-Forest" else "SVM"

        print(f"Selected algorithm: {train_algorithm}")
        os.makedirs(output_folder, exist_ok=True)

        stacked_raster_output = os.path.join(output_folder, "stacked_raster_output.tif")
        self.preProcessRaster(input_rasters, input_vector, output_folder, stacked_raster_output, skip_nodata_value=True)

        print("Loading ground truth data...")
        gt = self.load_ground_truth(train_points)
        print(f"Loaded {len(gt)} ground truth points")

        print("\nLoading parcel shapefile...")
        parcels = self.load_parcels(input_vector)
        print(f"Loaded {len(parcels)} parcels")

        #print("\nJoining ground truth with parcels...")
        training_parcels = gpd.sjoin(parcels, gt, how='inner', predicate='intersects')
        #print(f"Found {len(training_parcels)} parcels with ground truth")

        print("\nExtracting features for training parcels...")
        training_features = self.extract_features(stacked_raster_output, training_parcels)
        training_labels = training_parcels[label_field_name].values

        class_labels = np.unique(training_labels)
        print(f"Found {len(class_labels)} unique classes in the dataset: {class_labels}")

        print("\nTraining classification model...")
        model, conf_matrix, class_report, accuracy, predictions = self.train_model(
            training_features,
            training_labels,
            algorithm=train_algorithm,
            random_state=42
        )

        self.save_report(
            conf_matrix,
            class_report,
            accuracy,
            output_folder,
            class_labels
        )
        print(f"Reports saved in {output_folder}")

        print("\nClassifying all parcels...")
        all_features = self.extract_features(stacked_raster_output, parcels)
        classified_parcels = self.classify_parcels(model, parcels, all_features)

        output_shapefile = os.path.join(output_folder, "classified_parcels.shp")
        classified_parcels.to_file(output_shapefile)
        print(f"Classification results saved to {output_shapefile}")

        self.plot_results(classified_parcels, f'Parcel Classification ({train_algorithm})', output_folder)
        print("\nClassification completed!")

    #-------------------------------|
    # TWDTW Classification Method   |
    #-------------------------------|

    def classify_twdtw(self):
        print("classification TWDTW initiated")
        input_rasters = self.dlg.leInputRaster_twdtw.text()
        input_vector = self.dlg.leInputVector_twdtw.text()
        output_folder = self.dlg.leOutput_twdtw.text()
        timeline = self.dlg.leTimeline_twdtw.text()
        sample_projection = self.dlg.leSP_twdtw.text()
        field_samples = self.dlg.leFieldSamples_twdtw.text()
        split_percent = self.dlg.leSplit_twdtw.text()

        os.makedirs(output_folder, exist_ok=True)
        stacked_raster_output = os.path.join(output_folder, "stacked_raster_output.tif")

        self.preProcessRaster(input_rasters, input_vector, output_folder, stacked_raster_output, skip_nodata_value=True)

        twdtw_parameters = {
            'INPUT_RASTER': stacked_raster_output,
            'TIMELINE': timeline,
            'FIELD_SAMPLES': field_samples,
            'SAMPLE_PROJECTION': sample_projection,
            'SPLIT': float(split_percent)/100,
            'OUTPUT_FOLDER': output_folder,
        }
        print("TWDTW started..")
        processing.run("r:twdtw_classification", twdtw_parameters)
        print("TWDTW Completed.")

    #--------------------------------------------|
    # Feature Extraction and Processing Methods  |
    #--------------------------------------------|

    def load_ground_truth(self, csv_path):
        points_df = pd.read_csv(csv_path)
        geometry = [Point(x, y) for x, y in zip(points_df['longitude'], points_df['latitude'])]
        points_gdf = gpd.GeoDataFrame(points_df, geometry=geometry, crs="EPSG:4326")
        points_gdf = points_gdf.to_crs(epsg=32643)
        if 'from' in points_df.columns:
            points_df['from'] = pd.to_datetime(points_df['from'],  format='mixed', dayfirst=True)
        if 'to' in points_df.columns:
            points_df['to'] = pd.to_datetime(points_df['to'], format='mixed', dayfirst=True)
        return points_gdf

    def load_parcels(self, shapefile_path):
        return gpd.read_file(shapefile_path)

    def extract_features(self, raster_path, parcels):
        with rasterio.open(raster_path) as raster:
            geoms = [mapping(geom) for geom in parcels.geometry]
            num_splits = raster.count
            print(f"Processing raster with {num_splits} time splits")
            all_features = []
            for geom in geoms:
                parcel_feats = []
                for split in range(1, num_splits + 1):
                    stats = zonal_stats(
                        [geom],
                        raster.read(split),
                        affine=raster.transform,
                        stats=['mean','median','min','max','std','percentile_25','percentile_75'],
                        nodata=raster.nodata
                    )
                    s = stats[0]
                    basic_feats = [s.get('mean', np.nan),
                                s.get('median', np.nan),
                                s.get('min', np.nan),
                                s.get('max', np.nan),
                                s.get('std', np.nan),
                                s.get('percentile_25', np.nan),
                                s.get('percentile_75', np.nan)]
                    try:
                        out_image, _ = mask(raster, [geom], crop=True)
                        band_data = out_image[split-1]
                        valid_pixels = band_data[band_data != raster.nodata]
                        texture_feats = self.compute_glcm_features(valid_pixels)
                    except Exception as e:
                        print("Texture extraction error:", e)
                        texture_feats = [np.nan] * 6
                    parcel_feats.extend(basic_feats + texture_feats)
                all_features.append(parcel_feats)
        feature_matrix = np.array(all_features)
        print(f"Feature matrix shape: {feature_matrix.shape}")
        return feature_matrix

    def compute_glcm_features(self, pixels):
        if pixels.size == 0:
            return [np.nan] * 6
        min_val, max_val = pixels.min(), pixels.max()
        if max_val == min_val:
            scaled = np.zeros_like(pixels, dtype=np.uint8)
        else:
            scaled = ((pixels - min_val) / (max_val - min_val) * 255).astype(np.uint8)
        side = int(np.floor(np.sqrt(scaled.size)))
        if side < 2:
            return [np.nan] * 6
        img = scaled[:side*side].reshape((side, side))
        glcm = graycomatrix(img, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)
        contrast = graycoprops(glcm, 'contrast')[0, 0]
        dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]
        homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]
        energy = graycoprops(glcm, 'energy')[0, 0]
        correlation = graycoprops(glcm, 'correlation')[0, 0]
        asm = graycoprops(glcm, 'ASM')[0, 0]
        return [contrast, dissimilarity, homogeneity, energy, correlation, asm]

    #----------------------------------------|
    # Model Training and Evaluation Methods  |
    #----------------------------------------|

    def train_model(self, features, labels, algorithm='RF', random_state=42):
        #unique_classes = np.unique(labels)
        #print(f"Training with {len(unique_classes)} unique classes: {unique_classes}")
        
        imputer = SimpleImputer(strategy='mean')
        features_imputed = imputer.fit_transform(features)
        scaler = StandardScaler()
        features_scaled = scaler.fit_transform(features_imputed)

        ## split data input 
        split_percent = float(self.dlg.leSplit.text()) / 100.0

        X_train, X_test, y_train, y_test = train_test_split(
            features_scaled,
            labels,
            test_size = split_percent,
            random_state = random_state,
            stratify = labels
        )

        if algorithm.upper() == 'RF':
            rf_params = {
                'n_estimators': 1000,
                'max_depth': 10,
                'min_samples_split': 5,
                'min_samples_leaf': 2,
                'max_features': 'sqrt',
                'class_weight': 'balanced',
                'random_state': random_state
            }
            model = RandomForestClassifier(**rf_params)
        else:
            svm_params = {
                'kernel': 'rbf',
                'C': 1,
                'gamma': 0.1,
                'degree': 3,
                'class_weight': 'balanced',
                'probability': True,
                'random_state': random_state
            }
            model = SVC(**svm_params)
        
        #print(f"Training {algorithm} model on training split ({(1-split_percent)*100:.1f}% of data)....")

        model.fit(X_train, y_train)
        
        #y_test_pred = model.predict(X_test)
        #test_accuracy = accuracy_score(y_test,y_test_pred)
        #print(f"\nTest set accuracy: {test_accuracy*100:.2f}%")

        # Get predictions on entire dataset for full evaluation
        y_pred = model.predict(features_scaled)
        conf_matrix = confusion_matrix(labels, y_pred)
        class_report = classification_report(labels, y_pred)
        accuracy = accuracy_score(labels, y_pred)
        
        #print(f"\nModel Accuracy: {accuracy*100:.2f}%")
        
        return model, conf_matrix, class_report, accuracy, y_pred

    def classify_parcels(self, model, parcels, features):
        imputer = SimpleImputer(strategy='mean')
        features_imputed = imputer.fit_transform(features)
        scaler = StandardScaler()
        features_scaled = scaler.fit_transform(features_imputed)
        predictions = model.predict(features_scaled)
        parcels_classified = parcels.copy()
        parcels_classified['predicted_class'] = predictions
        return parcels_classified

    #---------------------------------------|
    # Reporting and Visualization Methods   |
    #---------------------------------------|

    def create_confusion_matrix_report(self, conf_matrix, class_labels, output_path):
        lines = [
            "Confusion Matrix Report\n",
            "=====================\n\n"
        ]
        
        header = "{:<20}".format("")
        for label in class_labels:
            header += "{:>12}".format(label)
        header += "{:>12}".format("Total")
        
        lines.append(header + "\n")
        
        row_totals = np.sum(conf_matrix, axis=1)
        for i, label in enumerate(class_labels):
            row = "{:<20}".format(label)
            for j in range(len(class_labels)):
                row += "{:>12}".format(conf_matrix[i][j])
            row += "{:>12}".format(row_totals[i])
            lines.append(row + "\n")
        
        col_totals = np.sum(conf_matrix, axis=0)
        total_row = "{:<20}".format("Total")
        for total in col_totals:
            total_row += "{:>12}".format(total)
        total_row += "{:>12}".format(np.sum(col_totals))
        lines.append(total_row + "\n")
        
        with open(output_path, 'w') as f:
            f.writelines(lines)

    def computeFromConfusionMatrix(self, output_matrix, training_report, class_labels):
        confusion_matrix = np.loadtxt(output_matrix, delimiter=',', dtype=int)
        
        total = np.sum(confusion_matrix)
        totalTrue = np.trace(confusion_matrix)
        classWiseData = []
        sumOfRowColumnProducts = 0

        if confusion_matrix.shape[0] != len(class_labels):
            raise ValueError(f"Mismatch between confusion matrix dimensions {confusion_matrix.shape} and number of classes {len(class_labels)}")

        lines = [
            "Accuracy Metrics Report\n",
            "=====================\n\n"
        ]

        for i in range(len(confusion_matrix)):
            row = confusion_matrix[i]
            column = confusion_matrix[:, i]
            rowSum = np.sum(row)
            columnSum = np.sum(column)
            sumOfRowColumnProducts += rowSum * columnSum

            classData = {}
            classData["TP"] = confusion_matrix[i, i]
            classData["FN"] = rowSum - classData["TP"]
            classData["FP"] = columnSum - classData["TP"]
            classData["TN"] = total - (classData["FP"] + classData["FN"] + classData["TP"])
            classData["precision"] = classData["TP"]/(classData["TP"]+classData["FP"]) if (classData["TP"]+classData["FP"]) > 0 else 0
            classData["recall"] = classData["TP"]/(classData["TP"]+classData["FN"]) if (classData["TP"]+classData["FN"]) > 0 else 0
            classData["f1-score"] = 2*classData["TP"]/(2*classData["TP"]+classData["FP"]+classData["FN"]) if (2*classData["TP"]+classData["FP"]+classData["FN"]) > 0 else 0
            classWiseData.append(classData)

        overall_accuracy = totalTrue/total * 100 if total > 0 else 0
        kappa = ((totalTrue*total)-sumOfRowColumnProducts)/(pow(total,2) - sumOfRowColumnProducts) if (pow(total,2) - sumOfRowColumnProducts) != 0 else 0

        header = "{:<20}".format("") + "\t".join(["{:>9}".format(label) for label in class_labels])
        lines.append(header + "\n")

        for prop in ["precision", "recall", "f1-score"]:
            row = "{:<20}".format(prop) + "\t".join(["{:>9.2f}".format(classData[prop]) for classData in classWiseData])
            lines.append(row + "\n")

        lines.extend([
            "\n\n",
            "{:<20}".format("Overall Accuracy")+"{:>9.2f}".format(overall_accuracy) + "\n",
            "{:<20}".format("Kappa")+"{:>9.2f}".format(kappa) + "\n"
        ])
        
        with open(training_report, "w") as file:
            file.writelines(lines)

    def save_report(self, conf_matrix, class_report, accuracy, output_folder, class_labels):
        #print(f"Processing {len(class_labels)} classes: {class_labels}")
        
        conf_matrix_path = os.path.join(output_folder, "confusion_matrix.txt")
        self.create_confusion_matrix_report(conf_matrix, class_labels, conf_matrix_path)
        
        matrix_path = os.path.join(output_folder, "temp_matrix.csv")
        np.savetxt(matrix_path, conf_matrix, delimiter=',', fmt='%d')
        
        accuracy_report_path = os.path.join(output_folder, "accuracy_report.txt")
        self.computeFromConfusionMatrix(matrix_path, accuracy_report_path, class_labels)
        
        os.remove(matrix_path)

    def plot_results(self, classified_parcels, title, output_folder):
        fig, ax = plt.subplots(figsize=(12, 8))
        classified_parcels.plot(column='predicted_class', categorical=True, legend=True, ax=ax)
        ax.set_title(title)
        plt.axis('off')
        plt.tight_layout()
        plot_file = os.path.join(output_folder, f"{title.replace(' ','_')}.png")
        plt.savefig(plot_file, bbox_inches="tight")
        plt.close(fig)

    #---------------------|
    # Main program        |
    #---------------------|

    def run(self):
        if self.first_start:
            self.first_start = False
            self.dlg = ClassificationDialog()
            
            # Set up algorithm selection
            self.dlg.cbAlgorithm.addItems(["Support Vector Machine", "Random-Forest", "TWDTW"])
            self.dlg.cbAlgorithm.currentTextChanged.connect(self.on_algorithm_changed)
            
            # Custom Inputs (RF/SVM)
            self.dlg.pbInputRaster.clicked.connect(self.select_input_rasters)   
            self.dlg.pbInputVector.clicked.connect(self.select_input_vector)
            self.dlg.pbPoints.clicked.connect(self.select_train_points)
            self.dlg.pbOutput.clicked.connect(self.select_output_folder)
            self.dlg.pbDzClassify.clicked.connect(self.classify_custom)
            self.dlg.helpButton.clicked.connect(self.openHelpTab)

            # TWDTW Inputs
            self.dlg.pbInputRaster_twdtw.clicked.connect(self.select_input_rasters_twdtw)   
            self.dlg.pbInputVector_twdtw.clicked.connect(self.select_input_vector_twdtw)
            self.dlg.pbTimeline_twdtw.clicked.connect(self.select_timeline_twdtw)
            self.dlg.pbSP_twdtw.clicked.connect(self.select_sample_projection_twdtw)
            self.dlg.pbFieldSamples_twdtw.clicked.connect(self.select_field_samples_twdtw)
            self.dlg.pbOutput_twdtw.clicked.connect(self.select_output_folder_twdtw)
            self.dlg.pbDzClassify_twdtw.clicked.connect(self.classify_twdtw)
            self.dlg.helpButton_twdtw.clicked.connect(self.openTWDTWHelpTab)

        self.dlg.show()
        result = self.dlg.exec_()

        # See if OK was pressed
        if result:
            # Do something useful here - delete the line containing pass and
            # substitute with your code.
            pass